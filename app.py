import streamlit as st
import openai
import json
from pathlib import Path
from qdrant_utils import init_qdrant, save_to_qdrant

# ğŸ” API keys from Streamlit secrets
openai.api_key = st.secrets["OPENAI_API_KEY"]
qdrant_client = init_qdrant()

# ğŸ“Š GPT model pricing
model_pricings = {
    "gpt-4o": {"Opis": "Multimodalny â€“ tekst, obraz, gÅ‚os", "Input": 2.5, "Output": 10.0},
    "gpt-4o-mini": {"Opis": "Lekki i tani do chatbotÃ³w", "Input": 0.15, "Output": 0.6},
    "gpt-4-turbo": {"Opis": "Szybki tekstowy model", "Input": 1.5, "Output": 6.0},
    "gpt-3.5-turbo": {"Opis": "BudÅ¼etowa opcja", "Input": 0.5, "Output": 1.5}
}
USD_TO_PLN = 3.97

# ğŸŒ TÅ‚umaczenia interfejsu
translations = {
    "Polski": {
        "title": "ğŸ§  MÃ³jGPT â€“ Inteligentny czat z pamiÄ™ciÄ…",
        "chat_title": "ğŸ’¬ Rozmowa",
        "input_placeholder": "Zadaj pytanie",
        "language_switch": "ğŸŒ JÄ™zyk interfejsu",
        "model_select": "ğŸ¤– Wybierz model GPT",
        "personality": "ğŸ­ Styl GPT",
        "memory_mode": "ğŸ§  Tryb pamiÄ™ci",
        "export_button": "ğŸ“¤ Eksportuj rozmowÄ™",
        "download_txt": "â¬‡ï¸ Pobierz jako TXT",
        "cost_usd": "ğŸ’° Koszt (USD)",
        "cost_pln": "ğŸ’° Koszt (PLN)",
        "default_personality": "JesteÅ› pomocnym, uprzejmym i zwiÄ™zÅ‚ym asystentem AI."
    },
    "Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°": {
        "title": "ğŸ§  MÑ–Ğ¹GPT â€“ Ğ†Ğ½Ñ‚ĞµĞ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ñ‡Ğ°Ñ‚ Ğ· Ğ¿Ğ°Ğ¼Ê¼ÑÑ‚Ñ‚Ñ",
        "chat_title": "ğŸ’¬ Ğ‘ĞµÑÑ–Ğ´Ğ°",
        "input_placeholder": "Ğ—Ğ°Ğ´Ğ°Ğ¹ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ",
        "language_switch": "ğŸŒ ĞœĞ¾Ğ²Ğ° Ñ–Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑÑƒ",
        "model_select": "ğŸ¤– Ğ’Ğ¸Ğ±ĞµÑ€Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ GPT",
        "personality": "ğŸ­ Ğ¡Ñ‚Ğ¸Ğ»ÑŒ GPT",
        "memory_mode": "ğŸ§  Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¿Ğ°Ğ¼Ê¼ÑÑ‚Ñ–",
        "export_button": "ğŸ“¤ Ğ•ĞºÑĞ¿Ğ¾Ñ€Ñ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ±ĞµÑÑ–Ğ´Ñƒ",
        "download_txt": "â¬‡ï¸ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ ÑĞº TXT",
        "cost_usd": "ğŸ’° Ğ’Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ (USD)",
        "cost_pln": "ğŸ’° Ğ’Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ (PLN)",
        "default_personality": "Ğ’Ğ¸ ĞºĞ¾Ñ€Ğ¸ÑĞ½Ğ¸Ğ¹, Ğ²Ğ²Ñ–Ñ‡Ğ»Ğ¸Ğ²Ğ¸Ğ¹ Ñ‚Ğ° Ğ»Ğ°ĞºĞ¾Ğ½Ñ–Ñ‡Ğ½Ğ¸Ğ¹ AI-Ğ¿Ğ¾Ğ¼Ñ–Ñ‡Ğ½Ğ¸Ğº."
    }
}

# ğŸ“‚ Lokalna pamiÄ™Ä‡
DB_PATH = Path("db")
DB_CONV_PATH = DB_PATH / "conversations"
DB_PATH.mkdir(exist_ok=True)
DB_CONV_PATH.mkdir(exist_ok=True)

# ğŸ¯ Detekcja tematu
def detect_topic(prompt):
    resp = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Podaj krÃ³tki temat tej rozmowy w 3â€“5 sÅ‚owach."},
            {"role": "user", "content": prompt}
        ]
    )
    return resp.choices[0].message.content.strip()

# ğŸ§  ZarzÄ…dzanie rozmowÄ…
def load_or_create_conversation():
    current_file = DB_PATH / "current.json"
    if not current_file.exists():
        convo = {
            "id": 1,
            "name": "Rozmowa 1",
            "chatbot_personality": translations["Polski"]["default_personality"],
            "messages": [],
            "model": "gpt-4o"
        }
        with open(DB_CONV_PATH / "1.json", "w") as f: json.dump(convo, f)
        with open(current_file, "w") as f: json.dump({"current_conversation_id": 1}, f)
    with open(current_file) as f: convo_id = json.load(f)["current_conversation_id"]
    with open(DB_CONV_PATH / f"{convo_id}.json") as f: convo = json.load(f)
    st.session_state.update(convo)

def save_conversation():
    convo = {
        "id": st.session_state["id"],
        "name": st.session_state["name"],
        "chatbot_personality": st.session_state["chatbot_personality"],
        "messages": st.session_state["messages"],
        "model": st.session_state["model"]
    }
    with open(DB_CONV_PATH / f"{convo['id']}.json", "w") as f: json.dump(convo, f)

def get_reply(prompt, memory, model, personality):
    msgs = [{"role": "system", "content": personality}] + memory + [{"role": "user", "content": prompt}]
    resp = openai.ChatCompletion.create(model=model, messages=msgs)
    usage = resp.usage or {}
    return {
        "role": "assistant",
        "content": resp.choices[0].message.content,
        "usage": {
            "prompt_tokens": usage.prompt_tokens,
            "completion_tokens": usage.completion_tokens,
            "total_tokens": usage.total_tokens
        }
    }

# ğŸš€ Start aplikacji
st.set_page_config(page_title="MÃ³jGPT", layout="centered")

# ğŸŒ JÄ™zyk interfejsu
lang = st.sidebar.selectbox("ğŸŒ JÄ™zyk interfejsu", ["Polski", "Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°"])
t = translations[lang]

if "id" not in st.session_state: load_or_create_conversation()
if st.session_state.get("chatbot_personality") not in [translations["Polski"]["default_personality"], translations["Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°"]["default_personality"]]:
    st.session_state["chatbot_personality"] = t["default_personality"]

# ğŸ§  Interfejs czatu
st.title(t["title"])
st.subheader(f"{t['chat_title']}: {st.session_state['name']}")

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

prompt = st.chat_input(t["input_placeholder"])
if prompt:
    st.session_state["messages"].append({"role": "user", "content": prompt})
    if len(st.session_state["messages"]) == 1:
        topic = detect_topic(prompt)
        st.session_state["name"] = topic[:50]

    mode = st.session_state.get("memory_mode", "Ostatnie 10 wiadomoÅ›ci")
    memory = st.session_state["messages"][-10:] if mode == "Ostatnie 10 wiadomoÅ›ci" else \
             st.session_state["messages"][-30:] if mode == "Rozszerzona (30)" else \
             st.session_state["messages"]

    reply = get_reply(prompt, memory, st.session_state["model"], st.session_state["chatbot_personality"])
    st.session_state["messages"].append(reply)
    with st.chat_message("assistant"): st.markdown(reply["content"])
    save_conversation()
    save_to_qdrant(prompt, reply["content"], f"Conv{st.session_state['id']}", qdrant_client)

# âš™ï¸ Sidebar
st.sidebar.markdown("---")
st.sidebar.header("âš™ï¸ " + t["model_select"])

st.session_state["model"] = st.sidebar.selectbox(
    t["model_select"], list(model_pricings.keys()),
    index=list(model_pricings.keys()).index(st.session_state["model"]),
    on_change=save_conversation
)

info = model_pricings[st.session_state["model"]]
st.sidebar.markdown(f"ğŸ“Œ *{info['Opis']}*")
st.sidebar.markdown(f"- Input: ${info['Input']} / 1M\n- Output: ${info['Output']} / 1M")

st.session_state["memory_mode"] = st.sidebar.selectbox(t["memory_mode"], ["Ostatnie 10 wiadomoÅ›ci", "Rozszerzona (30)", "PeÅ‚na historia"])

st.session_state["chatbot_personality"] = st.sidebar.text_area(
    t["personality"], value=st.session_state["chatbot_personality"],
    height=150, on_change=save_conversation
)

# ğŸ“¤ Eksport
if st.sidebar.button(t["export_button"]):
    chat_txt = "\n\n".join([
